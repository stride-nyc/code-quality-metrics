# .github/workflows/ai-code-drift-metrics.yml
# AI Code Drift Metrics - Tracks development patterns that may indicate problematic AI tool usage
# Based on research by Ken Judy - https://github.com/stride-nyc/code-quality-metrics
# Licensed under CC BY 4.0

name: AI Code Drift Metrics
on:
  schedule:
    - cron: '0 0 * * 0'  # Weekly on Sunday at midnight UTC
  workflow_dispatch:  # Allow manual runs

jobs:
  collect-metrics:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      issues: write
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history needed for branch analysis

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'

      - name: Collect AI Code Drift Metrics
        uses: actions/github-script@v7
        env:
          GITHUB_TOKEN: ${{ github.token }}
        with:
          script: |
            const fs = require('fs');
            
            async function collectMetrics() {
              const [owner, repo] = process.env.GITHUB_REPOSITORY.split('/');
              const since = new Date(Date.now() - 30 * 24 * 60 * 60 * 1000).toISOString();
              
              console.log(`Repository: ${owner}/${repo}`);
              console.log(`Looking for commits since: ${since}`);
              
              try {
                // Verify repository access
                const repoInfo = await github.rest.repos.get({ owner, repo });
                console.log(`Repository access confirmed: ${repoInfo.data.full_name}`);
                
                // Get all branches in the repository
                const branches = await github.paginate(github.rest.repos.listBranches, {
                  owner,
                  repo,
                  per_page: 100
                });
                
                // Filter to feature branches only (exclude main/master)
                const featureBranches = branches.filter(branch => 
                  !['main', 'master'].includes(branch.name.toLowerCase())
                );
                
                console.log(`Found ${branches.length} total branches`);
                console.log(`Analyzing ${featureBranches.length} feature branches: ${featureBranches.map(b => b.name).join(', ')}`);
                
                let allCommits = [];
                let branchCommitCounts = {};
                
                // Collect commits from each feature branch
                for (const branch of featureBranches) {
                  try {
                    console.log(`Fetching commits from branch: ${branch.name}`);
                    const branchCommits = await github.paginate(github.rest.repos.listCommits, {
                      owner,
                      repo,
                      sha: branch.name,
                      since,
                      per_page: 100
                    });
                    
                    branchCommitCounts[branch.name] = branchCommits.length;
                    allCommits = allCommits.concat(branchCommits.map(commit => ({
                      ...commit,
                      source_branch: branch.name
                    })));
                    
                    // Rate limiting to avoid API throttling
                    await new Promise(resolve => setTimeout(resolve, 200));
                    
                  } catch (error) {
                    console.log(`Error fetching commits from branch ${branch.name}: ${error.message}`);
                    branchCommitCounts[branch.name] = 0;
                  }
                }
                
                // Remove duplicate commits (same SHA appearing in multiple branches)
                const uniqueCommits = allCommits.filter((commit, index, self) => 
                  index === self.findIndex(c => c.sha === commit.sha)
                );
                
                console.log(`Found ${allCommits.length} total commits, ${uniqueCommits.length} unique commits`);
                console.log('Commits per branch:', branchCommitCounts);
                
                if (uniqueCommits.length === 0) {
                  console.log('No commits found in feature branches in the last 30 days.');
                  const emptyMetrics = [];
                  const summary = {
                    total_commits: 0,
                    branches_analyzed: featureBranches.map(b => b.name),
                    branch_commit_counts: branchCommitCounts,
                    large_commits_pct: "0.00",
                    sprawling_commits_pct: "0.00", 
                    test_first_pct: "0.00",
                    avg_files_changed: "0.00",
                    avg_lines_changed: "0.00",
                    note: "Feature branches only - main/master excluded from analysis"
                  };
                  
                  fs.writeFileSync('commit_metrics.json', JSON.stringify(emptyMetrics, null, 2));
                  fs.writeFileSync('metrics_summary.json', JSON.stringify(summary, null, 2));
                  return;
                }
                
                const metrics = [];
                console.log(`Processing ${Math.min(uniqueCommits.length, 50)} commits for detailed analysis...`);
                
                // Analyze up to 50 commits in detail
                for (const commit of uniqueCommits.slice(0, 50)) {
                  try {
                    const detail = await github.rest.repos.getCommit({
                      owner,
                      repo,
                      ref: commit.sha
                    });
                    
                    // Classify files as test or production
                    // NOTE: Adjust regex patterns for your project's test file conventions
                    const testFiles = detail.data.files?.filter(f =>
                      /\.(test|spec)\.|Tests?\.cs$|Test\.cs$|__tests__|\/tests?\//i.test(f.filename)
                    ) || [];
                    
                    const prodFiles = detail.data.files?.filter(f =>
                      !/\.(test|spec)\.|Tests?\.cs$|Test\.cs$|__tests__|\/tests?\//i.test(f.filename)
                    ) || [];
                    
                    metrics.push({
                      sha: commit.sha,
                      date: commit.commit.committer.date,
                      message: commit.commit.message.split('\n')[0],
                      author: commit.commit.author.name,
                      source_branch: commit.source_branch,
                      total_additions: detail.data.stats.additions,
                      total_deletions: detail.data.stats.deletions,
                      files_changed: detail.data.files?.length || 0,
                      test_files_count: testFiles.length,
                      prod_files_count: prodFiles.length,
                      test_first_indicator: testFiles.length > 0 && prodFiles.length > 0,
                      large_commit: (detail.data.stats.additions + detail.data.stats.deletions) > 100,
                      sprawling_commit: (detail.data.files?.length || 0) > 5,
                      commit_type: "feature_branch"
                    });
                    
                    // Rate limiting between detailed commit analysis
                    await new Promise(resolve => setTimeout(resolve, 100));
                  } catch (error) {
                    console.log(`Error processing commit ${commit.sha}: ${error.message}`);
                  }
                }
                
                // Save detailed metrics
                console.log(`Saving metrics for ${metrics.length} commits`);
                fs.writeFileSync('commit_metrics.json', JSON.stringify(metrics, null, 2));
                
                // Calculate summary statistics
                const summary = {
                  total_commits: metrics.length,
                  filtered_from: uniqueCommits.length,
                  branches_analyzed: featureBranches.map(b => b.name),
                  branch_commit_counts: branchCommitCounts,
                  large_commits_pct: (metrics.filter(m => m.large_commit).length / metrics.length * 100).toFixed(2),
                  sprawling_commits_pct: (metrics.filter(m => m.sprawling_commit).length / metrics.length * 100).toFixed(2),
                  test_first_pct: (metrics.filter(m => m.test_first_indicator).length / metrics.length * 100).toFixed(2),
                  avg_files_changed: (metrics.reduce((sum, m) => sum + m.files_changed, 0) / metrics.length).toFixed(2),
                  avg_lines_changed: (metrics.reduce((sum, m) => sum + m.total_additions + m.total_deletions, 0) / metrics.length).toFixed(2),
                  note: "Feature branches only - main/master excluded from analysis",
                  analysis_date: new Date().toISOString(),
                  workflow_version: "1.0"
                };
                
                fs.writeFileSync('metrics_summary.json', JSON.stringify(summary, null, 2));
                console.log('Analysis complete. Summary:', summary);
                
              } catch (error) {
                console.error('Error in collectMetrics:', error);
                throw error;
              }
            }
            
            await collectMetrics();

      - name: Upload Metrics Artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: ai-code-drift-metrics-${{ github.run_number }}
          path: |
            commit_metrics.json
            metrics_summary.json
          if-no-files-found: warn

      - name: Create Weekly Report Issue
        if: github.event_name == 'schedule'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            
            try {
              const summary = JSON.parse(fs.readFileSync('metrics_summary.json', 'utf8'));
              
              // Create interpretation guidance
              const interpretations = [];
              if (parseFloat(summary.large_commits_pct) > 20) {
                interpretations.push('⚠️ **Large commits above 20% threshold** - Consider breaking down AI-generated code into smaller, focused commits');
              }
              if (parseFloat(summary.sprawling_commits_pct) > 10) {
                interpretations.push('⚠️ **Sprawling commits above 10% threshold** - Review if AI suggestions are causing scattered changes');
              }
              if (parseFloat(summary.test_first_pct) < 30) {
                interpretations.push('⚠️ **Low test-first discipline** - Consider strengthening TDD practices when using AI tools');
              }
              if (parseFloat(summary.avg_lines_changed) > 500) {
                interpretations.push('⚠️ **High average lines changed** - May indicate batch acceptance of AI-generated code');
              }
              
              if (interpretations.length === 0) {
                interpretations.push('✅ **Metrics look healthy** - Development patterns appear well-controlled');
              }
              
              const body = `
              ## AI Code Drift Metrics Report
              
              **Analysis Period:** Last 30 days  
              **Commits Analyzed:** ${summary.total_commits} (from ${summary.filtered_from} total)  
              **Branches Analyzed:** ${summary.branches_analyzed?.join(', ') || 'None'}  
              
              ### Key Metrics
              
              | Metric | Value | Target | Status |
              |--------|-------|--------|---------|
              | Large Commits (>100 lines) | ${summary.large_commits_pct}% | <20% | ${parseFloat(summary.large_commits_pct) > 20 ? '⚠️' : '✅'} |
              | Sprawling Commits (>5 files) | ${summary.sprawling_commits_pct}% | <10% | ${parseFloat(summary.sprawling_commits_pct) > 10 ? '⚠️' : '✅'} |
              | Test-First Discipline | ${summary.test_first_pct}% | Trending ↗ | ${parseFloat(summary.test_first_pct) < 30 ? '⚠️' : '✅'} |
              | Avg Files Changed | ${summary.avg_files_changed} | <5 | ${parseFloat(summary.avg_files_changed) > 5 ? '⚠️' : '✅'} |
              | Avg Lines Changed | ${summary.avg_lines_changed} | <100 | ${parseFloat(summary.avg_lines_changed) > 100 ? '⚠️' : '✅'} |
              
              ### Interpretation
              
              ${interpretations.join('\n')}
              
              ### Branch Activity
              ${Object.entries(summary.branch_commit_counts || {}).map(([branch, count]) => `- **${branch}**: ${count} commits`).join('\n')}
              
              ---
              
              **About these metrics:** This analysis helps detect AI code drift patterns by examining development behavior before merge squashing destroys the signals. For more information, see the [AI Code Drift Metrics article](https://github.com/yourrepo/your-article).
              
              _Generated by AI Code Drift Metrics Workflow v${summary.workflow_version}_
              `;
              
              await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: `AI Code Drift Metrics Report - ${new Date().toISOString().split('T')[0]}`,
                body: body,
                labels: ['metrics', 'ai-code-drift', 'automated']
              });
              
            } catch (error) {
              console.error('Error creating report issue:', error);
            }